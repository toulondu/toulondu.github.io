<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"toulondu.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Transformer来自Google 2017年的一篇文章，在原来的Attention&amp;RNN模型上抛弃了RNN，用全attention的结构取得了更好的效果。这里做一做自己学习的笔记，也算一个简单的介绍。内容图片很多来自于原论文Attention Is All You Need和The Illustrated Transformer这篇文章。 结构原论文给出的结构如下：  可以看到由左">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer模型简介(笔记)">
<meta property="og:url" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Toulon&#39;s BLOG">
<meta property="og:description" content="Transformer来自Google 2017年的一篇文章，在原来的Attention&amp;RNN模型上抛弃了RNN，用全attention的结构取得了更好的效果。这里做一做自己学习的笔记，也算一个简单的介绍。内容图片很多来自于原论文Attention Is All You Need和The Illustrated Transformer这篇文章。 结构原论文给出的结构如下：  可以看到由左">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/structureOfTransformer.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/encodersAndDecoders.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/EachEncoder.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformerSelfAttentionVectors.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/SelfAttentionScore.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionSoftmax.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionOutput.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionMatrixCalculation.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformer_attention_heads_weight_matrix_o.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/encoderTotalLook.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformer_positional_encoding_vectors.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/PosEncodingformula.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/resInEncoder.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/resInTransformer.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/structureOfTransformer.png">
<meta property="og:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformerDecodingGif.gif">
<meta property="article:published_time" content="2020-04-02T14:04:42.000Z">
<meta property="article:modified_time" content="2020-04-02T14:21:58.348Z">
<meta property="article:author" content="Toulon Du">
<meta property="article:tag" content="Model">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/structureOfTransformer.png">

<link rel="canonical" href="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Transformer模型简介(笔记) | Toulon's BLOG</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Toulon's BLOG</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Algorithm</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://toulondu.github.io/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Toulon Du">
      <meta itemprop="description" content="Sharing Knowledge And Learn More">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Toulon's BLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Transformer模型简介(笔记)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-04-02 22:04:42 / 修改时间：22:21:58" itemprop="dateCreated datePublished" datetime="2020-04-02T22:04:42+08:00">2020-04-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Transformer来自Google 2017年的一篇文章，在原来的Attention&amp;RNN模型上抛弃了RNN，用全attention的结构取得了更好的效果。<br>这里做一做自己学习的笔记，也算一个简单的介绍。<br>内容图片很多来自于原论文<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention Is All You Need</a>和<a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a>这篇文章。</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>原论文给出的结构如下：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/structureOfTransformer.png" class="" title="transformer结构">
<p>可以看到由左右两个部分，左边的Encoders和右边的Decoders组成。两边都有一个”N×”,表示各自由N个同样的结构重复N次组成，原文中是6。就是下面图中的样子。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/encodersAndDecoders.png" class="" title="展开">

<h2 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h2><p>我们来看一看Encoder部分。</p>
<p>因为是NLP的案例，所以我们首先要把我们的输入数据，即词变成词向量，这通过embedding实现，embedding后的数据作为Encoder的输入。<br>虽然有很多encoder，但embedding只用在最下面一层的encoder上，其它的encoder都是用上一层encoder的输出作为输入。</p>
<p>每个encoder都是一样的结构，都由两个子结构组成：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/EachEncoder.png" class="" title="encoder组成">

<p>self-attention的作用是，当你在处理某个具体的词时，self-attention允许你从句子中的其它位置处寻找线索，从而对当前词的理解和预测起到帮助。</p>
<h3 id="self-attention-细节"><a href="#self-attention-细节" class="headerlink" title="self-attention 细节"></a>self-attention 细节</h3><p>计算self-attention主要有以下几个步骤</p>
<p><strong>第一步</strong><br>计算self-attention的第一步是从每个输入向量中创建出3个向量(Querry,Key,Value)。他们通过把embedding分别与三个矩阵相乘得到，三个矩阵通过训练过程得到。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformerSelfAttentionVectors.png" class="" title="QSV">

<p>Q,S,V较之embedding的维度要小，在文中的维度是64，而embedding的维度是512。不必完全一样，但这是一种使得计算比较稳定的结构选择。</p>
<ul>
<li>Q = WQ * x</li>
<li>K = WK * x</li>
<li>V = WV * x</li>
</ul>
<p><strong>第二步</strong><br>计算self-attention的第二步是计算一个score。 假设我们正在计算的句子的第一个单词为”Thinking”。我们需要把输入的句子中的每一个词与这个词运算来得到一个score，这个score决定了我们在encode当前词的时候句子其它位置所施加的影响。</p>
<p>计算方法是把当前次的Q与要计算的词的K值进行点乘。即如果我们要计算#1位置处的self-attention，第一个我们要计算的score将是把q1和k1点乘，第二个socre则是把q1和k2进行点乘。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/SelfAttentionScore.png" class="" title="计算score">


<p><strong>第三步和第四步</strong><br>第三步和第四步是将得到的score除以8，这个8是QKV向量的维度64的平方根。这可以让梯度更加稳定(直接归一值差距较大)。当然可以不是8，这里只是一个默认值。接着将结果传递给一个softmax操作，这将把socre的值标准化，使它们都为正，且和为1。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionSoftmax.png" class="" title="计算权重">

<p><strong>第五步</strong><br>第五步是将每个V与第四步的结果相乘。这一步从直觉上讲是保留当前词想要关注的其它词语的完整性，同时丢掉不相关的词语(通过乘以了非常小的数)。</p>
<p><strong>第六步</strong><br>将得到的带权重的数据向量相加。这将得到self-attention层在这个位置(我们这里是第一个词)的输出。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionOutput.png" class="" title="encoder输出">

<p>这就是self-attentionde的计算过程，结果向量我们将传递给接下来的 feed-forward nertal network处理。<br>当然，在实际实现中，这些计算都可以通过矩阵形式的计算从而更加快速。</p>
<p><strong>self-attention的矩阵计算</strong><br>使用矩阵，第二步到第六步实际上可以在一个公式内进行计算：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/selfAttentionMatrixCalculation.png" class="" title="矩阵计算公式">



<h3 id="multi-headed"><a href="#multi-headed" class="headerlink" title="multi-headed"></a>multi-headed</h3><p>文章进一步用一个叫做”multi-headed” attention的结构增强了self-attention。它从2个方面提升了attention层的表现：<br><strong>扩张了模型关注其他位置的能力</strong><br>在我们上面的例子中，对thinking的编码就包含了句中其它位置词的影响(当然，最大的影响依然是它自己)。在解析一些有明显指向性的代词时就显得非常有用。比如“The animal didn’t cross the street because it was too tired”中的”it”指代的谁。<br><strong>给了attention层多重”表述子空间”</strong><br>这主要通过多组[WQ,WK,QV]来实现，文中使用了8组WQ,WK,QV，这些矩阵都通过随机初始化赋值。即是说我们会得到8组QKV，从而得到8个输出矩阵。每一个都是输入数据的一个表述子空间。</p>
<p>在传递给feed-forward network前，我们需要将他们处理成一个矩阵。通过将这8个矩阵堆叠起来，再与一个权重矩阵WO相乘得到。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformer_attention_heads_weight_matrix_o.png" class="" title="concat结果">

<p>以上大概就是 multi-headed self-attention 的内容。原文将他们放到一张图上：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/encoderTotalLook.png" class="" title="整体造型">

<h3 id="position-encoding"><a href="#position-encoding" class="headerlink" title="position encoding"></a>position encoding</h3><p>因为放弃了使用RNN，那么句子中词与词的位置关系就被忽略了，文中使用了一种position encoding的方式将位置信息补入模型中。<br>这通过给每一个input embedding加上一个vector来实现。这些vector遵循一种<strong><em>特殊的模式</em></strong>，它存储了每个词的位置信息，通过把它与embedding相加，从而把这种信息代入到后面的QKV和点乘的计算过程中。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformer_positional_encoding_vectors.png" class="" title="位置编码">

<p>如果我们的embedding是512维的向量，那么要加的positional encoding 向量也是512维。</p>
<p>关于位置编码，文中使用的是三角函数的形式。</p>
<p>大概说一下什么是位置编码和为什么要使用三角函数。<br>要对位置进行编码，最简单的方式莫过于直接使用单词在文本中的位置，即1，2，3，…，N。但缺点过于明显，如果文本较长，那么位置编码的大小跨度就太大了，将这样的数据加入到模型训练中，很有可能是会喧宾夺主的抢占embedding的重要性。<br>同样，将刚才的顺序除以文本长度也是不行的，如1/N,2/N,3/N,…1。<br>我们需要位置信息，其中一个重要的信息就是相对位置信息，而这种处理方式，会导致相隔同样距离的两个词，在长度不同的文本中得到的相对位置信息不一致，甚至差距较大。<br>总结之后，那么真正适合用来做位置编码的函数似乎就是 连续且有界的周期性函数。有界保证值域不会太大，周期性保证一定程度上编码的差异会摆脱文本长度的影响，而连续则保证了两个比较靠近的词不会出现差距很大的情况。</p>
<p>于是文中使用了sin和cos函数，连续而且周期稳定，值域[-1,1]。</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/PosEncodingformula.png" class="" title="位置编码公式">

<p>加入了dmodel和i两个参数，dmodel是embedding的维度，在文中就是512，用于增大位置编码的空间表现范围。i为向量的某一维度，dmodel=512，那么i就是[0,255],这样在奇偶维度分别使用sin和cos。这样就从取值范围和取值方法两个方向上增加了取值的多样性。让位置编码更加科学。</p>
<p>当然，这个函数作者应该也是通过自身的经验与不断的实验得到的。</p>
<p>PS：GOOGLE BERT中用了新的取位置信息的方法，position embedding，这是后话。</p>
<h3 id="残差网络-Residual-network-的使用"><a href="#残差网络-Residual-network-的使用" class="headerlink" title="残差网络(Residual network)的使用"></a>残差网络(Residual network)的使用</h3><p>另一个细节，就是哪里跑不掉的resNet的使用：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/resInEncoder.png" class="" title="resNet的使用">

<p>同样，在decoder中也使用到了resNet，如果是一个2个encoder和decoder的transformer，它长这样：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/resInTransformer.png" class="" title="resNet的使用2">

<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>介绍完Encoder，大多数Decoder里的组件的作用也明朗了。接下来看看他哥俩如何一起工作。</p>
<p>再贴一下模型结构图：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/structureOfTransformer.png" class="" title="transformer结构">
<p>可以看到Decoder中有一个 Encoder-Decoder Attention 层，它接受Encoder部分最后的输出作为计算attention的Key和Value，接受它下面的self-attention层的输出作为Query。</p>
<p>其次，Decoder部分的self-attention层也与Encoder中的不同，不同于Encoder中计算单词两两间的attention，Decoder中计算的是当前单词和它前面的单词的attention，同样，也要加入位置信息。</p>
<p>文章中有张非常形象的动图：</p>
<img src="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/transformerDecodingGif.gif" class="" title="transformer结构">

<p>注意在decoder中做self-attention的时候，当前输入只应该看到当前时刻以前的输出，比如在输出第二个词的时候，输入中是不应该出现第三个词的信息的。文中处理这种情况的方法是用了一个倒三角矩阵(第i行j列的元素表示第i个输入和第j个输入的attention)，将对角线右侧元素全部设置为负无穷，这样就防止了模型看到未来的信息。</p>
<h2 id="最后一层"><a href="#最后一层" class="headerlink" title="最后一层"></a>最后一层</h2><p>decoder将输出一堆floats组成的向量，将它转换成词语，就是最后一层的工作(通常是一个Linear+Softmax)。</p>
<p>Linear layer是一个简单的全连接层，将decoder的输出投射为一个比原来大很多的向量，叫做logits vector。</p>
<p>如果我们的词空间有10000个单词，那么10000就是这个logits vector的维度，向量中每个元素对应一个具体的词。接下来你就清楚了，softmax的作用是将这个logits vector的结果变成概率，概率最高的元素对应的词就是我们的输出。</p>
<h2 id="关于训练"><a href="#关于训练" class="headerlink" title="关于训练"></a>关于训练</h2><p>todo…</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>todo…</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a><br><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention Is All You Need</a><br><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">哈佛大学的pytorch版本源码</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Model/" rel="tag"># Model</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/" rel="prev" title="实现一个简单的人脸识别系统">
      <i class="fa fa-chevron-left"></i> 实现一个简单的人脸识别系统
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/03/BERT%E7%AC%94%E8%AE%B0-%E7%AE%80%E4%BB%8B/" rel="next" title="BERT笔记-简介">
      BERT笔记-简介 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#结构"><span class="nav-number">1.</span> <span class="nav-text">结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#encoder"><span class="nav-number">2.</span> <span class="nav-text">encoder</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#self-attention-细节"><span class="nav-number">2.1.</span> <span class="nav-text">self-attention 细节</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-headed"><span class="nav-number">2.2.</span> <span class="nav-text">multi-headed</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#position-encoding"><span class="nav-number">2.3.</span> <span class="nav-text">position encoding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#残差网络-Residual-network-的使用"><span class="nav-number">2.4.</span> <span class="nav-text">残差网络(Residual network)的使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decoder"><span class="nav-number">3.</span> <span class="nav-text">Decoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最后一层"><span class="nav-number">4.</span> <span class="nav-text">最后一层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于训练"><span class="nav-number">5.</span> <span class="nav-text">关于训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码"><span class="nav-number">6.</span> <span class="nav-text">代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">7.</span> <span class="nav-text">参考</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Toulon Du</p>
  <div class="site-description" itemprop="description">Sharing Knowledge And Learn More</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Toulon Du</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
