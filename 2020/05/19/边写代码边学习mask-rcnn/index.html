<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="Sharing Knowledge And Learn More">
  <meta name="author" content="Toulon Du">
  <meta name="keywords" content="">
  <title>边写代码边学习Mask-rcnn - Toulon&#39;s BLOG</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Toulon's Secret</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              目录</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-05-19 00:42">
                    2020年5月19日 凌晨
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    3.5k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    44
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>作为一个深度学习的学习者，你是不是苦于自己看了非常多的理论却难以下手实践？是否总觉得自己还没到写代码的时候？<br>如果你这么想，那么你看再多的理论，也无法真正踏进深度学习的大门。<br>就我个人而言，很多时候即使读完了论文仍然有点懵，很多地方感觉都一知半解，还有些地方可能直接就是不太明白。此时，如果能有源码看一看，才能真正将这篇文章搞明白。<br>so, “talk is cheap, show me the code” 实乃金玉良言。</p>
<p>这篇文章将使用pytorch modelzoo提供的现成Mask R-CNN预训练模型来进行fine-turing，实现一个目标检测和语义分割应用。并且在这个过程中来重新复习一下Mask R-CNN这个经典网络的一些原理。  </p>
<h2 id="Mask-R-CNN简介"><a href="#Mask-R-CNN简介" class="headerlink" title="Mask R-CNN简介"></a>Mask R-CNN简介</h2><p>Mask R-CNN来自何恺明大神2017年的论文，是一个通用的目标检测和实例分割的模型。它基于作者团队在2015年提出的faster rcnn模型，最主要的改动就是增加了一个分支来用于分割任务。<br>Mask R-CNN是anchor-based的模型，依然采用Faster RCNN的2-stage结构，首先用RPN找出候选region，然后在此基础上计算ROI并完成分类、检测和分割任务。<br>并没有添加各种trick，Mask RCNN就超过了当时所有的sota模型。</p>
<h2 id="定义DataSet并处理"><a href="#定义DataSet并处理" class="headerlink" title="定义DataSet并处理"></a>定义DataSet并处理</h2><p>我们将使用Penn-Fudan数据库中的行人图片数据来对模型进行微调。它包含170个图像和345个行人实例。<a href="https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip" target="_blank" rel="noopener">数据在此</a>。<br>数据文件结构大致如下：</p>
<pre><code class="hljs plain">PennFudanPed&#x2F;
  PedMasks&#x2F;
    FudanPed00001_mask.png
    FudanPed00002_mask.png
    FudanPed00003_mask.png
    FudanPed00004_mask.png
    ...
  PNGImages&#x2F;
    FudanPed00001.png
    FudanPed00002.png
    FudanPed00003.png
    FudanPed00004.png</code></pre>
<p>PedMasks中数据为PNGImages文件夹下对应图片的实例分割掩膜，如下：</p>
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/mask_sample.png" srcset="/img/loading.gif" class="" title="原图片">
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/mask_sample1.png" srcset="/img/loading.gif" class="" title="mask图片">
<p>即掩膜中不同的数值对应不同的实例的分割。</p>
<h3 id="定义Dataset类"><a href="#定义Dataset类" class="headerlink" title="定义Dataset类"></a>定义Dataset类</h3><p>上一篇文章说过，Dataset类是帮助我们处理原始数据并产出模型需要的输入数据的类。<br>而在我们这次的Mask R-CNN模型中，我们希望Dataset通过<strong>getitem</strong>能返回我们图像数据(H,W)以及图像的以下信息：</p>
<ul>
<li>boxes: 这张图片里所有的目标区域,格式为[x0,x1,y0,y1]，x∈[0,W], y∈[0,H]</li>
<li>labels: 每个边框的标签</li>
<li>masks: 每个图像的掩膜</li>
<li>image_id: 图片id</li>
<li>area：每个bbox的面积，用于计算IoU</li>
<li>iscrowd: 每个区域是否是人群<br>代码如下：<pre><code class="hljs plain">class PennFudanDataset(Dataset):
    def __init__(self, root, transforms):
        self.root &#x3D; root
        self.transforms &#x3D; transforms
        # 下载所有图像文件，为其排序。确保它们对齐,而且这样就把图片名字列出来了，方便了加载图片
        self.imgs &#x3D; list(sorted(os.listdir(os.path.join(root, &quot;PNGImages&quot;))))
        self.masks &#x3D; list(sorted(os.listdir(os.path.join(root, &quot;PedMasks&quot;))))

    def __getitem__(self, idx):
        # load images ad masks
        img_path &#x3D; os.path.join(self.root, &quot;PNGImages&quot;, self.imgs[idx])
        mask_path &#x3D; os.path.join(self.root, &quot;PedMasks&quot;, self.masks[idx])
        img &#x3D; Image.open(img_path).convert(&quot;RGB&quot;)
        # 请注意我们还没有将mask转换为RGB,
        # 因为每种颜色对应一个不同的实例。0是背景
        mask &#x3D; Image.open(mask_path)
        # 将PIL图像转换为numpy数组
        mask &#x3D; np.array(mask)
        # 实例被编码为不同的颜色
        obj_ids &#x3D; np.unique(mask)
        # 第一个id是背景(即0)，所以删除它
        obj_ids &#x3D; obj_ids[1:]

        # 将相同颜色编码的mask分成一组
        # mask为2维，用None扩充obj_ids维度，masks为3维，因为一张图片可能有多个实例分割
        # 二进制格式
        masks &#x3D; mask &#x3D;&#x3D; obj_ids[:, None, None]

        # 获取每个mask的边界框坐标
        num_objs &#x3D; len(obj_ids)
        boxes &#x3D; []
        for i in range(num_objs):
            # masks[i]为2维，所以np.where返回2个tuple，分别为此颜色编码的元素在各个维度的下标
            # 这里的数据中不同颜色的mask是语义分割的像素点，选出最大最小的x坐标和y坐标就得到了目标区域(x0,y0),(x1,y1)
            pos &#x3D; np.where(masks[i])
            xmin &#x3D; np.min(pos[1])
            xmax &#x3D; np.max(pos[1])
            ymin &#x3D; np.min(pos[0])
            ymax &#x3D; np.max(pos[0])
            boxes.append([xmin, ymin, xmax, ymax])

        # 将所有转换为torch.Tensor
        boxes &#x3D; torch.as_tensor(boxes, dtype&#x3D;torch.float32)
        # 我们只检测行人这一个类(行人，所以直接全部置为1)
        labels &#x3D; torch.ones((num_objs,), dtype&#x3D;torch.int64)
        masks &#x3D; torch.as_tensor(masks, dtype&#x3D;torch.uint8)

        image_id &#x3D; torch.tensor([idx])
        area &#x3D; (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        # 假设所有实例都不是人群
        iscrowd &#x3D; torch.zeros((num_objs,), dtype&#x3D;torch.int64)

        target &#x3D; &#123;&#125;
        target[&quot;boxes&quot;] &#x3D; boxes  # 这张图片里所有的目标区域
        target[&quot;labels&quot;] &#x3D; labels   # 每个目标区域的类型
        target[&quot;masks&quot;] &#x3D; masks    # 图像掩膜 mask
        target[&quot;image_id&quot;] &#x3D; image_id  # 图片id
        target[&quot;area&quot;] &#x3D; area          # 每个区域的面积
        target[&quot;iscrowd&quot;] &#x3D; iscrowd    # 每个区域是否是人群(这里假设的都不是)

        if self.transforms is not None:
            img, target &#x3D; self.transforms(img, target)

        return img, target
        
    def __len__(self):
        return len(self.imgs)</code></pre>

</li>
</ul>
<h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><p>Mask-RCNN结构如下：</p>
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/mask_rcnn_model.jpg" srcset="/img/loading.gif" class="" title="模型结构">
<p>torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) 为我们提供了一个预训练的Mask-RCNN模型。<br>修改这种预训练模型一般有2种思路，第一就是当我们数据较少时，我们就只将最后一层替换成我们的输入目标，然后进行微调。<br>另一种思路则是可以在原模型基础上进行修改，比如替换backbone，修改RPN的anchor数量，调整ROI维度等。  </p>
<p>我们先来看看第二种方式：<br><strong>修改backbone</strong>: Mask-RCNN 的backbone使用的Resnet101，整体还是比较大的，假如你想使用一些轻量的backbone，比如mobileNet，那么你可以进行替换<br><strong>修改rpn</strong>:Mask-RCNN 的anchor是如何生成的呢，注意看上面的结构图。输入数据在经过backbone之后，得到的feature-map其实是在原输入的基础上进行了32倍下采样。基于这个feature-map的每个元素，我们再进行一个3×3的卷积来增加感受野，然后对每个元素生成9个anchor来生成候选区域。这9个初始anchor包含3种长宽比(1:1,1:2,2:1),每种长宽比包含3种不同的面积。结构如下：</p>
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/rpn_structure.jpg" srcset="/img/loading.gif" class="" title="rpn结构">
<p>注意图上的各种数字，256表示的是骨干网络输出的通道数，k表示生成的anchor的数量。因为每个anchor有positive和negative，所以有2k个打分。而每个anchor会经过后续的回归找到针对正确区域的4个偏移量(x,y,w,h)，所以是4k个coordinates。<br>对于这些参数，我们也可以修改。<br><strong>修改RoI pooling</strong>：RoI pooling层复杂收集proposal，然后选取特征并送入后续的分类和检测FC网络。 要知道为了保留图片中事物的特性，我们很少对图片采用resize或者裁剪操作，而Mask-RCNN接受不同大小的图片输入，那么经过骨干和RPN网络后，各图片到此时的数据维度是不一样的。这种情况下我们没有办法通过FC等网络进行特征组合。RoI pooling层就是来解决这个问题的。它将收集到的proposal分为固定个数的区域(比如7*7)，然后对每这些区域使用max_pool处理，这样就得到了固定维度的输出。<br>其次，Faster RCNN在处理RoI pooling的过程中有2次取整操作：</p>
<ul>
<li>region proposal的xywh通常是小数，但是为了方便操作会把它整数化。</li>
<li>将整数化后的边界区域平均分割成 k x k 个单元，对每一个单元的边界进行整数化。<br>这将会导致RoI pooling后的输出与原图像对应的区域产生一些偏离，导致不能完全对应。第一个问题很好解决，不再取整即可。而解决第二个问题，则是使用双线性插值的方式来更加精确的找到每个边界的特征。我们在下面代码中看到的sampling_ratio=2就是这个方法的体现。</li>
</ul>
<p>代码如下：</p>
<pre><code class="hljs plain">from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator

# 加载预先训练的模型进行分类和返回
# 只有功能 
# 主干采用mobileNet V2
backbone &#x3D; torchvision.models.mobilenet_v2(pretrained&#x3D;True).features
# FasterRCNN需要知道骨干网中的输出通道数量。对于mobilenet_v2，它是1280，所以我们需要在这里添加它
backbone.out_channels &#x3D; 1280

# 我们让RPN在每个空间位置生成5 x 3个锚点 PS：这里原文是3*3，即3种大小3种宽高比
# 改成5种不同的大小和3种不同的宽高比。 
# 因为每个特征映射可能具有不同的大小和宽高比，size为anchor box大小，aspect_ratios则是宽高比
anchor_generator &#x3D; AnchorGenerator(sizes&#x3D;((32, 64, 128, 256, 512),),
                                   aspect_ratios&#x3D;((0.5, 1.0, 2.0),))

# 定义一下我们将用于执行感兴趣区域裁剪的特征映射，以及重新缩放后裁剪的大小。 
# 如果您的主干返回Tensor，则featmap_names应为[0]。 
# 更一般地，主干应该返回OrderedDict [Tensor]
# 并且在featmap_names中，您可以选择要使用的功能映射。
# 这里为RoIPooling层，将feature_map对应的原图中部分处理成7*7(output_size&#x3D;7)的大小然后再进行后续的分类和回归操作
# 而sampling_ratio&#x3D;2则是原文中进行插值所选取的采样点，简单的说：采样点为2就是说7*7的每个区域内，都要再分成2*2个grid，然后对每个grid中心点进行采样，将这4个点的值求平均就是这个区域最终的值。
roi_pooler &#x3D; torchvision.ops.MultiScaleRoIAlign(featmap_names&#x3D;[0],
                                                output_size&#x3D;7,
                                                sampling_ratio&#x3D;2)

# 将这些pieces放在FasterRCNN模型中
model &#x3D; FasterRCNN(backbone,
                   num_classes&#x3D;2,
                   rpn_anchor_generator&#x3D;anchor_generator,
                   box_roi_pool&#x3D;roi_pooler)</code></pre>


<p>虽然第二种方式明显比较酷，但鉴于本示例中样本数据比较少，所以我们使用第一种方式:</p>
<pre><code class="hljs plain">def get_model_instance_segmentation(num_classes):
    # 加载在COCO上预训练的预训练的实例分割模型
    model &#x3D; torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained&#x3D;True)

    # 获取分类器的输入特征数
    in_features &#x3D; model.roi_heads.box_predictor.cls_score.in_features
    # 用新的头部替换预先训练好的头部
    model.roi_heads.box_predictor &#x3D; FastRCNNPredictor(in_features, num_classes)

    # 现在获取掩膜分类器的输入特征数
    in_features_mask &#x3D; model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer &#x3D; 256
    # 并用新的掩膜预测器替换掩膜预测器
    model.roi_heads.mask_predictor &#x3D; MaskRCNNPredictor(in_features_mask,
                                                       hidden_layer,
                                                       num_classes)</code></pre>


<h2 id="实例化模型"><a href="#实例化模型" class="headerlink" title="实例化模型"></a>实例化模型</h2><p>在torchvision的官方库中，references/detection/里有很多辅助函数来简化训练和评估检测模型。<br>这里我们需要用到references/detection/engine.py，references/detection/utils.py和references/detection/transforms.py。<br>去<a href="https://github.com/pytorch/vision" target="_blank" rel="noopener">这里</a> download代码并将这几个文件拷贝到你的目录中即可。</p>
<p>其次，提前安装<a href="https://github.com/cocodataset/cocoapi/tree/master/PythonAPI" target="_blank" rel="noopener">cocoapi</a>,如果你在windows上，可能需要安装visial studio。<br>windows上也可以通过安装pycocotools来解决。whl见：<a href="https://pypi.org/project/pycocotools-windows/#files" target="_blank" rel="noopener">https://pypi.org/project/pycocotools-windows/#files</a></p>
<p>这一步没什么好说的，代码里也有足够的注释：</p>
<pre><code class="hljs plain"># 训练阶段按0.5几率水平翻转图像
def get_transform(train):
    transforms &#x3D; []
    transforms.append(T.ToTensor())
    if train:
        transforms.append(T.RandomHorizontalFlip(0.5))
    return T.Compose(transforms)


# 在GPU上训练，若无GPU，可选择在CPU上训练
device &#x3D; torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;)

# 我们的数据集只有两个类 - 背景和人
num_classes &#x3D; 2
# 使用我们的数据集和定义的转换
dataset &#x3D; PennFudanDataset(&#39;data&#x2F;PennFudanPed&#39;, get_transform(train&#x3D;True))
dataset_test &#x3D; PennFudanDataset(&#39;data&#x2F;PennFudanPed&#39;, get_transform(train&#x3D;False))

# 在训练和测试集中拆分数据集
indices &#x3D; torch.randperm(len(dataset)).tolist()
dataset &#x3D; torch.utils.data.Subset(dataset, indices[:-50])
dataset_test &#x3D; torch.utils.data.Subset(dataset_test, indices[-50:])

# 定义训练和验证数据加载器
data_loader &#x3D; torch.utils.data.DataLoader(
    dataset, batch_size&#x3D;2, shuffle&#x3D;True, num_workers&#x3D;4,
    collate_fn&#x3D;utils.collate_fn)

data_loader_test &#x3D; torch.utils.data.DataLoader(
    dataset_test, batch_size&#x3D;1, shuffle&#x3D;False, num_workers&#x3D;4,
    collate_fn&#x3D;utils.collate_fn)

# 使用我们的辅助函数获取模型
model &#x3D; get_model_instance_segmentation(num_classes)

# 将我们的模型迁移到合适的设备
model.to(device)</code></pre>

<h2 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h2><p>我们使用SGD进行优化，训练10个epoch。并且通过比较在测试集上的mAP，保存效果最好的参数到best_state_dict中。</p>
<pre><code class="hljs plain">def train():
    # 构造一个优化器
    params &#x3D; [p for p in model.parameters() if p.requires_grad]
    optimizer &#x3D; torch.optim.SGD(params, lr&#x3D;0.005,
                                momentum&#x3D;0.9, weight_decay&#x3D;0.0005)
    # 和学习率调度程序
    lr_scheduler &#x3D; torch.optim.lr_scheduler.StepLR(optimizer,
                                                   step_size&#x3D;3,
                                                   gamma&#x3D;0.1)

    # 训练10个epochs
    num_epochs &#x3D; 10

    best_mAp &#x3D; 0
    for epoch in range(num_epochs):
        # 训练一个epoch，每10次迭代打印一次
        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq&#x3D;10)
        # 更新学习速率
        lr_scheduler.step()
        # 在测试集上评价
        eval_res &#x3D; evaluate(model, data_loader_test, device&#x3D;device)

        # 将结果最好的参数保存下来
        mAp_epoch &#x3D; float(eval_res.coco_eval[&#39;bbox&#39;].stats[0])
        if mAp_epoch &gt; best_mAp:
            torch.save(model.state_dict(),&#39;.&#x2F;best_state_dict&#39;)
            best_mAp &#x3D; mAp_epoch

    print(&quot;Finish training the model.&quot;)</code></pre>
<p>训练过程中你可以看到各项指标，我忘了截图，最后的COCO-style mAP大概是81左右，mask mAP为在78左右。</p>
<h2 id="使用效果最好的参数进行预测"><a href="#使用效果最好的参数进行预测" class="headerlink" title="使用效果最好的参数进行预测"></a>使用效果最好的参数进行预测</h2><p>完成了训练，接下来肯定就是我们的show time了。</p>
<pre><code class="hljs plain">model.load_state_dict(torch.load(&#39;.&#x2F;best_state_dict&#39;))
    # # 切换为评估模式
    model.eval()

    # 让我们瞅一瞅效果
    img, _ &#x3D; dataset_test[0]

    with torch.no_grad():
        prediction &#x3D; model([img.to(device)])

    img_ori &#x3D; Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())
    draw &#x3D; ImageDraw.Draw(img_ori)

    masks &#x3D; prediction[0][&#39;masks&#39;]
    masks_all &#x3D; Image.fromarray(np.sum(np.sum(masks.mul(255).byte().cpu().numpy(),axis&#x3D;0),axis&#x3D;0))
    
    
    for [x1,y1,x2,y2] in prediction[0][&#39;boxes&#39;]:
        draw.rectangle([(x1,y1),(x2,y2)],outline&#x3D;(255,0,0))

    imgs &#x3D; [img_ori,masks_all]

    for i,im in enumerate(imgs):
        ax &#x3D; plt.subplot(1, 2, i + 1)
        plt.tight_layout()
        ax.axis(&#39;off&#39;)
        plt.imshow(im)

    plt.show()</code></pre>
<p>效果如下：</p>
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/result01.jpg" srcset="/img/loading.gif" class="" title="效果图1">
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/result02.jpg" srcset="/img/loading.gif" class="" title="效果图2">
<img src="/2020/05/19/%E8%BE%B9%E5%86%99%E4%BB%A3%E7%A0%81%E8%BE%B9%E5%AD%A6%E4%B9%A0mask-rcnn/result03.jpg" srcset="/img/loading.gif" class="" title="效果图3">

<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>本文源码在<a href="https://github.com/toulondu/mask-rcnn-brief" target="_blank" rel="noopener">这里</a></p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p><a href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" target="_blank" rel="noopener">pytorch官网教程:TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL</a><br><a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN 论文</a><br><a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">Mask R-CNN 论文</a>、<br><a href="https://zhuanlan.zhihu.com/p/37998710" target="_blank" rel="noopener">令人拍案称奇的Mask RCNN</a></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/coding/">coding</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a>
                    
                      <a class="hover-with-bg" href="/tags/Mask-R-CNN/">Mask R-CNN</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%AE%9E%E8%B7%B5/">实践</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/05/28/React%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E7%9F%A5%E8%AF%86%E7%82%B9-%E5%9F%BA%E6%9C%AC/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">React官方文档知识点-基本</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/05/15/PyTorch%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%A4%84%E7%90%86/">
                        <span class="hidden-mobile">PyTorch中的数据加载和处理</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'https://toulondu.github.io/2020/05/19/边写代码边学习mask-rcnn/';
        this.page.identifier = '/2020/05/19/边写代码边学习mask-rcnn/';
      };
      var oldLoadDq = window.onload;
      window.onload = function () {
        oldLoadDq && oldLoadDq();

        var d = document, s = d.createElement('script');
        s.type = 'text/javascript';
        s.src = '//' + 'Toulon' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      };
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noopener">comments
        powered by Disqus.</a></noscript>
  </div>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "边写代码边学习Mask-rcnn&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>


















</body>
</html>
