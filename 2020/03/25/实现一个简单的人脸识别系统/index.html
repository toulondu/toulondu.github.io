<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"toulondu.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="下述的大多数方法来自 FaceNet,也叫做DeepFace. 脸部识别一般来说，脸部识别问题可以分为两类：  脸部验证(Face Verification)：”这是某个人吗？” 通过提供的输入的数据来识别是否是某个确定的人。比如机场系统扫描你的护照来确认你是否是正确的持有人，比如移动手机通过识别你的脸部确认你是拥有者从而解锁。总的来说，这是一个1对1匹配的问题。 脸部识别(Face Recogn">
<meta property="og:type" content="article">
<meta property="og:title" content="实现一个简单的人脸识别系统">
<meta property="og:url" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="Toulon&#39;s BLOG">
<meta property="og:description" content="下述的大多数方法来自 FaceNet,也叫做DeepFace. 脸部识别一般来说，脸部识别问题可以分为两类：  脸部验证(Face Verification)：”这是某个人吗？” 通过提供的输入的数据来识别是否是某个确定的人。比如机场系统扫描你的护照来确认你是否是正确的持有人，比如移动手机通过识别你的脸部确认你是拥有者从而解锁。总的来说，这是一个1对1匹配的问题。 脸部识别(Face Recogn">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/LisaFaceReco.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/FaceNetFx.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/lossFormulaSingle.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/lossFormulaTotal.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/L2formula.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/Lisa.png">
<meta property="og:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/camera_Lisa.png">
<meta property="article:published_time" content="2020-03-25T07:27:57.000Z">
<meta property="article:modified_time" content="2020-03-25T08:36:29.486Z">
<meta property="article:author" content="Toulon Du">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/LisaFaceReco.png">

<link rel="canonical" href="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>实现一个简单的人脸识别系统 | Toulon's BLOG</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Toulon's BLOG</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Algorithm</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://toulondu.github.io/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Toulon Du">
      <meta itemprop="description" content="Sharing Knowledge And Learn More">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Toulon's BLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          实现一个简单的人脸识别系统
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-25 15:27:57 / 修改时间：16:36:29" itemprop="dateCreated datePublished" datetime="2020-03-25T15:27:57+08:00">2020-03-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>下述的大多数方法来自 <strong><em><a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener">FaceNet</a></em></strong>,也叫做<strong><em>DeepFace</em></strong>.</p>
<h2 id="脸部识别"><a href="#脸部识别" class="headerlink" title="脸部识别"></a>脸部识别</h2><p>一般来说，脸部识别问题可以分为两类：</p>
<ul>
<li>脸部验证(Face Verification)：”这是某个人吗？” 通过提供的输入的数据来识别是否是某个确定的人。比如机场系统扫描你的护照来确认你是否是正确的持有人，比如移动手机通过识别你的脸部确认你是拥有者从而解锁。总的来说，这是一个1对1匹配的问题。</li>
<li>脸部识别(Face Recognition)：”这是谁？” 通过提供的输入识别来识别对应的人是谁。比如公司的脸部识别打卡，通过识别脸部直接完成对应人员的打卡。总的来说，这是一个1对K的匹配问题。</li>
</ul>
<p>FaceNet 通过一个神经网络先将输入的脸部照片解码为一个128维向量，通过比较2个这样的向量，从而判断这两张图片是否是一个人。将输入数据与数据库中所有人员的照片进行对比，从而找到”这是谁”。</p>
<p>我们将用TensorFlow来实现这个程序：(tensorflow 1.X)</p>
<ul>
<li>1.实现三元损失函数</li>
<li>2.用一个预训练的模型来将脸部图片解码为128维的向量</li>
<li>3.使用这些代码来进行脸部验证和脸部识别</li>
</ul>
<p>另外，我们使用通道优先(channels-first)。 也就是说对于输入数据的维度表示，我们使用(m,nC,nH,nW), 而不是(m,nH,nW,nC)。当然，channels-first 和 channels-last都有各自的理由，至今社区也没有一个统一的标准。</p>
<h3 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h3><p>先导入包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate</span><br><span class="line">from keras.models import Model</span><br><span class="line">from keras.layers.normalization import BatchNormalization</span><br><span class="line">from keras.layers.pooling import MaxPooling2D, AveragePooling2D</span><br><span class="line">from keras.layers.merge import Concatenate</span><br><span class="line">from keras.layers.core import Lambda, Flatten, Dense</span><br><span class="line">from keras.initializers import glorot_uniform</span><br><span class="line">from keras.engine.topology import Layer</span><br><span class="line">from keras import backend as K</span><br><span class="line">K.set_image_data_format(&#39;channels_first&#39;)</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">from numpy import genfromtxt</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from fr_utils import *</span><br><span class="line">from inception_blocks_v2 import *</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold&#x3D;np.nan)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="0-简陋的脸部识别"><a href="#0-简陋的脸部识别" class="headerlink" title="0.简陋的脸部识别"></a>0.简陋的脸部识别</h2><p>在脸部验证中，你需要确定给到的两张图片是否是一个人。最简单的方法就是直接将两张图片一个像素一个像素的进行比较。如果两张图片间的间距小于某个阈值，他们可能就是一个人。</p>
<img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/LisaFaceReco.png" class="" title="逐像素比较">

<p>不难想到这个算法的表现会很差。因为光线的变化、人物脸部方向、甚至是头部位置的微小变化，都会导致像素值的改变。</p>
<p>与其使用原图片，我们可以使用编码后的图片数据。即f(img)。</p>
<p>将图片编码后的数据进行元素级的比较，我们可以得到一个更加准确的关于脸部验证的结果。</p>
<hr>
<h2 id="1-将脸部图片编码为128维的向量"><a href="#1-将脸部图片编码为128维的向量" class="headerlink" title="1.将脸部图片编码为128维的向量"></a>1.将脸部图片编码为128维的向量</h2><h3 id="1-1-使用卷积网络来进行编码"><a href="#1-1-使用卷积网络来进行编码" class="headerlink" title="1.1 使用卷积网络来进行编码"></a>1.1 使用卷积网络来进行编码</h3><p>FaceNet模型需要使用非常多的数据和很长的时间来进行训练。这里我们跳过这个步骤，直接载入别人已经训练好的权重。 网络结构采用了 <a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szegedy等人</a>文中的inception模型。 我们使用一个已经实现好的inception network的实现(在inception_blocks_v2.py中，略)。</p>
<p>几个需要知道的知识点：</p>
<ul>
<li>这个网络采用96×96维度的RGB图像作为输入。特别地，输入一个脸部照片(或者多批次的m照片组)作为张量，形状为：(m,nC,nH,nW) = (m,3,96,96)</li>
<li>它将输出一个(m,128)的矩阵，即将每一张图片都编码为128维的向量。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FRmodel &#x3D; faceRecoModel(input_shape&#x3D;(3, 96, 96))</span><br><span class="line">print(&quot;Total Params:&quot;, FRmodel.count_params())</span><br></pre></td></tr></table></figure>
<p>输出：Total Params: 3743280</p>
<p>通过使用一个128元的全连接层作为它的最后一层，这就保证了模型将输出128维的向量。接着，使用这两个向量进行两张图片的比较：</p>


<p>如果编码符合以下判别标准，则是一个好的编码:</p>
<ul>
<li>对同一个人的不同图片的编码较为相似</li>
<li>对不同人的图片的编码差异较大</li>
</ul>
<p>三元损失函数将以上标准公式化了，并且试图将相同人的图片的编码缩小，将不同人图片的编码拉大。</p>
<h3 id="1-2-三元损失函数对于一张图片x，我们声明它的编码为f-x-f是由神经网络计算的方法。"><a href="#1-2-三元损失函数对于一张图片x，我们声明它的编码为f-x-f是由神经网络计算的方法。" class="headerlink" title="1.2 三元损失函数对于一张图片x，我们声明它的编码为f(x), f是由神经网络计算的方法。"></a>1.2 三元损失函数对于一张图片x，我们声明它的编码为f(x), f是由神经网络计算的方法。</h3><img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/FaceNetFx.png" class="" title="f(x)方法">

<p>三元损失函数的训练需要用到三元组数据，每个三元组包含三张图片(A,P,N)</p>
<ul>
<li>A 是一张锚图片 - 某人的头部图像</li>
<li>P 是一张”正”图片 - 与A图片中是同一个人物</li>
<li>N 是一张”负”图片 - 与A图片中不是同一个人物</li>
</ul>
<p>我们用(A(i),P(i),N(i))(都是上标)来声明第i个训练样本。<br>我们希望图A(i)与P(i)的距离至少比A(i)和N(i)的距离近至少一个α的值：</p>
<img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/lossFormulaSingle.png" class="" title="单个样本的三元损失公式">
<p>那么总的损失函数就是：</p>
<img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/lossFormulaTotal.png" class="" title="三元损失公式">
<p>[z]+表示 max(z,0)。表示一旦A与P距离和A与N距离达到我们的要求，损失就为0，否则它的值就是损失值。</p>
<p><strong><em>Notes:</em></strong></p>
<ul>
<li>公式中的第一个部分是锚图片A和正图片P的距离，你希望它尽可能的小</li>
<li>公式的第二个部分则是锚图片A和负图片N的距离，你希望它相对较大</li>
<li>α叫做边距(margin)，这是一个人为选择的超参数，我们使用 α = 0.2</li>
</ul>
<p>大多数的实现里会将编码后的向量进行一次L2归一化，这里我们不用担心~</p>
<p>实现上面公式中的三元损失函数，需要4个步骤：</p>
<ol>
<li>计算锚图片A和正图片P间的距离</li>
<li>计算锚图片A和负图片N间的距离</li>
<li>对每个三元组样本进行公式计算</li>
<li>将每组样本经步骤3得到的值与0取max并取和</li>
</ol>
<p>PS：</p>
<img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/L2formula.png" class="" title="L2 Norm计算方法">

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">def triplet_loss(y_true, y_pred, alpha &#x3D; 0.2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    三元损失函数的实现</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    y_true -- true 标签, 当你在keras中定义loss时需要, 在这个方法中你不需要它.</span><br><span class="line">    y_pred -- python list 包含三个对象:</span><br><span class="line">            anchor -- 锚图片编码后的结果, 形状为 (None, 128)</span><br><span class="line">            positive -- 正图片编码后的结果, 形状为(None, 128)</span><br><span class="line">            negative -- 负图片编码后的结果, 形状为 (None, 128)</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    loss -- 数字, 损失值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    anchor, positive, negative &#x3D; y_pred[0], y_pred[1], y_pred[2]</span><br><span class="line">    </span><br><span class="line">    # Step 1</span><br><span class="line">    pos_dist &#x3D; tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),-1)</span><br><span class="line">    # Step 2</span><br><span class="line">    neg_dist &#x3D; tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),-1)</span><br><span class="line">    # Step 3</span><br><span class="line">    basic_loss &#x3D; tf.maximum(tf.add(tf.subtract(pos_dist,neg_dist),alpha),0)</span><br><span class="line">    # Step 4</span><br><span class="line">    loss &#x3D; tf.reduce_sum(basic_loss)</span><br><span class="line">    </span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="2-载入预训练模型"><a href="#2-载入预训练模型" class="headerlink" title="2.载入预训练模型"></a>2.载入预训练模型</h2><p>FaceNet通过最小化三元损失函数来进行训练。但训练需要大量的数据和计算时间，这里我们就不从头训练了。我们直接读取一个预训练的模型。用下面的代码读取来读取一个模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FRmodel.compile(optimizer &#x3D; &#39;adam&#39;, loss &#x3D; triplet_loss, metrics &#x3D; [&#39;accuracy&#39;])</span><br><span class="line">load_weights_from_FaceNet(FRmodel)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3-应用模型"><a href="#3-应用模型" class="headerlink" title="3.应用模型"></a>3.应用模型</h2><p>假定我们构建的这个系统是一个门禁系统，用于给某公司利用脸部识别来确定是否允许某人进入公司建筑。</p>
<p>要通过门禁，每个人要先在入口处刷门禁卡，脸部识别系统会识别他们是否是他们所声明的人。</p>
<h3 id="3-1-脸部识别"><a href="#3-1-脸部识别" class="headerlink" title="3.1 脸部识别"></a>3.1 脸部识别</h3><p>我们先建立一个数据库，它存放了所有被允许进入建筑人员的编码后向量数据。它将用到img_to_encoding(image_path,model)方法，这个方法在输入图片数据上通过模型的前向传播来获得结果。</p>
<p>因为是教程，简便起见，我们直接用一个dict来充当数据库：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">database &#x3D; &#123;&#125;</span><br><span class="line">database[&quot;danielle&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;danielle.png&quot;, FRmodel)</span><br><span class="line">database[&quot;younes&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;younes.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;tian&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;tian.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;andrew&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;andrew.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;kian&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;kian.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;dan&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;dan.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;sebastiano&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;sebastiano.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;bertrand&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;bertrand.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;kevin&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;kevin.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;felix&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;felix.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;benoit&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;benoit.jpg&quot;, FRmodel)</span><br><span class="line">database[&quot;arnaud&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;arnaud.jpg&quot;, FRmodel)</span><br></pre></td></tr></table></figure>

<p>接下来，当一个人走到前门处并刷卡，你就可以从数据库中查找他的编码，然后再进行脸部匹配，主要以下几个步骤：</p>
<ol>
<li>将前门摄像机捕捉的图片进行编码</li>
<li>计算上一步的编码与数据库中找到的对应id人员的编码间的间距</li>
<li>如果间距小于0.7，开门</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def verify(image_path, identity, database, model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    验证存放在image_path中的人是否和数据库identity对应的人是同一个</span><br><span class="line">    </span><br><span class="line">    参数:</span><br><span class="line">    image_path -- 图片地址</span><br><span class="line">    identity -- string, 要识别者的名字(来自于刷卡id). 必须是建筑进入允许的人员.</span><br><span class="line">    database -- python dictionary 数据字典 人名:头像编码 (向量).</span><br><span class="line">    model -- keras的 inception 模型</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    dist -- image_path存储的图像和identity对应的图像的间距</span><br><span class="line">    door_open -- True代表开门，False代表不开门</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # Step 1:</span><br><span class="line">    encoding &#x3D; img_to_encoding(image_path,model)</span><br><span class="line">    </span><br><span class="line">    # Step 2: </span><br><span class="line">    dist &#x3D; np.linalg.norm(encoding - database[identity])</span><br><span class="line">    # Step 3: </span><br><span class="line">    if dist &lt; 0.7:</span><br><span class="line">        print(&quot;It&#39;s &quot; + str(identity) + &quot;, welcome in!&quot;)</span><br><span class="line">        door_open &#x3D; True</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;It&#39;s not &quot; + str(identity) + &quot;, please go away&quot;)</span><br><span class="line">        door_open &#x3D; False</span><br><span class="line">        </span><br><span class="line">    return dist, door_open</span><br></pre></td></tr></table></figure>
<p>用了 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html" target="_blank" rel="noopener">np.linalg.norm</a>来计算间距，不传递第二个参数即计算F-范数。</p>
<p>我们传入一张正确的图片试一试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">verify(&quot;images&#x2F;camera_0.jpg&quot;, &quot;younes&quot;, database, FRmodel)</span><br></pre></td></tr></table></figure>
<p>输出：It’s younes, welcome in!</p>
<p>再来一张错误的呢：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">verify(&quot;images&#x2F;camera_2.jpg&quot;, &quot;kian&quot;, database, FRmodel)</span><br></pre></td></tr></table></figure>
<p>输出：It’s not kian, please go away</p>
<h3 id="3-2-脸部识别"><a href="#3-2-脸部识别" class="headerlink" title="3.2 脸部识别"></a>3.2 脸部识别</h3><p>脸部认证系统基本完成了，但是如果系统内某人丢失了ID卡，他再次回到办公室就不能再进去了！(需要刷卡)</p>
<p>要解决这个问题，你就需要将系统改造成一个脸部识别系统。这样大家就都不需要带id卡了。一个被授权的人只要走到前门，门就会自动打开！</p>
<p>很简单，只需要一个遍历，直接上代码即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">def who_is_it(image_path, database, model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    实现脸部识别系统，识别image_path图片人的身份</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    略</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    min_dist -- image_path图片与数据库中图片的最小间距</span><br><span class="line">    identity -- 最小间距对应的人</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    encoding &#x3D; img_to_encoding(image_path,model)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    # 初始化最小值，整大点</span><br><span class="line">    min_dist &#x3D; 100</span><br><span class="line">    </span><br><span class="line">    for (name, db_enc) in database.items():</span><br><span class="line">        </span><br><span class="line">        dist &#x3D; np.linalg.norm(encoding - db_enc)</span><br><span class="line"></span><br><span class="line">        if dist &lt; min_dist:</span><br><span class="line">            min_dist &#x3D; dist</span><br><span class="line">            identity &#x3D; name</span><br><span class="line"></span><br><span class="line">    if min_dist &gt; 0.7:</span><br><span class="line">        print(&quot;Not in the database.&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print (&quot;it&#39;s &quot; + str(identity) + &quot;, the distance is &quot; + str(min_dist))</span><br><span class="line">        </span><br><span class="line">    return min_dist, identity</span><br></pre></td></tr></table></figure>
<p>试一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">who_is_it(&quot;images&#x2F;camera_0.jpg&quot;, database, FRmodel)</span><br></pre></td></tr></table></figure>
<p>输出：it’s younes, the distance is 0.659393</p>
<p>激动人心的时候来了，我们把Lisa的图片裁剪成96×96再放入：</p>
<img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/Lisa.png" class="" title="Lisa"> <img src="/2020/03/25/%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/camera_Lisa.png" class="" title="LisaInCamera">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">database[&quot;lisa&quot;] &#x3D; img_to_encoding(&quot;images&#x2F;Lisa.png&quot;, FRmodel)</span><br><span class="line">who_is_it(&quot;images&#x2F;camera_Lisa.png&quot;, database, FRmodel)</span><br></pre></td></tr></table></figure>
<p>输出： it’s lisa, the distance is 0.597898<br>成功！！！</p>
<p>这样，一个简陋版本的脸部识别系统就完成啦！</p>
<h3 id="一些提升的方法"><a href="#一些提升的方法" class="headerlink" title="一些提升的方法"></a>一些提升的方法</h3><p>这里就不一一实现了，还有一些可以提升算法效果的方法：</p>
<ul>
<li>对于每个人，多在数据库中放几张照片，比如不同角度的，不同光线的，不同时间的。在刷脸时，将之与数据库中每个人的多张图片进行比较，这样可以提高模型准确度。</li>
<li>运用一个裁剪算法，将图片尽量剪到只剩下脸部。这样可以尽量排除不相关因素的干扰，也能提高准确度。</li>
</ul>
<hr>
<h2 id="引用："><a href="#引用：" class="headerlink" title="引用："></a>引用：</h2><ul>
<li>Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). <a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a></li>
<li>Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, Lior Wolf (2014). <a href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf" target="_blank" rel="noopener">DeepFace: Closing the gap to human-level performance in face verification</a></li>
<li>The pretrained model we use is inspired by Victor Sy Wang’s implementation and was loaded using his code: <a href="https://github.com/iwantooxxoox/Keras-OpenFace" target="_blank" rel="noopener">https://github.com/iwantooxxoox/Keras-OpenFace</a>.</li>
<li>Our implementation also took a lot of inspiration from the official FaceNet github repository: <a href="https://github.com/davidsandberg/facenet" target="_blank" rel="noopener">https://github.com/davidsandberg/facenet</a></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/" rel="prev" title="卷积神经网络介绍">
      <i class="fa fa-chevron-left"></i> 卷积神经网络介绍
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/02/Transformer%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E7%AC%94%E8%AE%B0/" rel="next" title="Transformer模型简介(笔记)">
      Transformer模型简介(笔记) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#脸部识别"><span class="nav-number">1.</span> <span class="nav-text">脸部识别</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#导入包"><span class="nav-number">1.1.</span> <span class="nav-text">导入包</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0-简陋的脸部识别"><span class="nav-number">2.</span> <span class="nav-text">0.简陋的脸部识别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-将脸部图片编码为128维的向量"><span class="nav-number">3.</span> <span class="nav-text">1.将脸部图片编码为128维的向量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-使用卷积网络来进行编码"><span class="nav-number">3.1.</span> <span class="nav-text">1.1 使用卷积网络来进行编码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-三元损失函数对于一张图片x，我们声明它的编码为f-x-f是由神经网络计算的方法。"><span class="nav-number">3.2.</span> <span class="nav-text">1.2 三元损失函数对于一张图片x，我们声明它的编码为f(x), f是由神经网络计算的方法。</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-载入预训练模型"><span class="nav-number">4.</span> <span class="nav-text">2.载入预训练模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-应用模型"><span class="nav-number">5.</span> <span class="nav-text">3.应用模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-脸部识别"><span class="nav-number">5.1.</span> <span class="nav-text">3.1 脸部识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-脸部识别"><span class="nav-number">5.2.</span> <span class="nav-text">3.2 脸部识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一些提升的方法"><span class="nav-number">5.3.</span> <span class="nav-text">一些提升的方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#引用："><span class="nav-number">6.</span> <span class="nav-text">引用：</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Toulon Du</p>
  <div class="site-description" itemprop="description">Sharing Knowledge And Learn More</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Toulon Du</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
